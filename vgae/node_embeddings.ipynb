{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "\n",
    "import dgl\n",
    "\n",
    "import model\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from dgl.data import CiteseerGraphDataset, CoraGraphDataset, PubmedGraphDataset\n",
    "# from input_data import load_data\n",
    "\n",
    "import torch\n",
    "from dgl.data import DGLDataset\n",
    "\n",
    "from preprocess import (\n",
    "    mask_test_edges,\n",
    "    mask_test_edges_dgl,\n",
    "    preprocess_graph,\n",
    "    sparse_to_tuple,\n",
    ")\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 170 µs (started: 2023-05-19 09:44:59 -05:00)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/miniconda3/envs/Conda_vgae_3.10/lib/python3.10/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/ealvarez/miniconda3/envs/Conda_vgae_3.10/lib/python3.10/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/ealvarez/miniconda3/envs/Conda_vgae_3.10/lib/python3.10/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/ealvarez/miniconda3/envs/Conda_vgae_3.10/lib/python3.10/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.4 s (started: 2023-05-19 09:44:59 -05:00)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.42 ms (started: 2023-05-19 09:45:02 -05:00)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/Project\n",
      "Method:\t\t dgi\n",
      "Group:\t\t ['WT', 5]\n",
      "Subgroup:\t ['1', '2', '3', '4', '5']\n",
      "Dimensions:\t [3]\n",
      "time: 1.67 ms (started: 2023-05-19 10:14:19 -05:00)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "  \n",
    "# Opening JSON file\n",
    "file = open(\"parameters.json\")\n",
    "params = json.load(file)\n",
    "\n",
    "dir = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "print(dir)\n",
    "\n",
    "method = params[\"method\"][params[\"method_idx\"]]\n",
    "print(\"Method:\\t\\t\", method)\n",
    "\n",
    "group = params[\"group\"][params[\"group_idx\"]]\n",
    "print(\"Group:\\t\\t\", group)\n",
    "\n",
    "subgroups = [str(k + 1) for k in range(group[1])]\n",
    "print(\"Subgroup:\\t\", subgroups)\n",
    "\n",
    "dimensions = params[\"dimensions\"]\n",
    "print(\"Dimensions:\\t\", dimensions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.14 ms (started: 2023-05-19 09:45:02 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Custom dataset\n",
    "\n",
    "class CustomDataset(DGLDataset):\n",
    "    def __init__(self, name, dir, group, subgroup):\n",
    "        self.dir = dir\n",
    "        self.group = group\n",
    "        self.subgroup = subgroup\n",
    "        super().__init__(name=name)\n",
    "       \n",
    "    def process(self):\n",
    "        nodes_data = pd.read_csv(\"{}/output_preprocessing/graph_data/{}_nodes_data_{}.csv\".format(self.dir, self.group, self.subgroup))\n",
    "        edges_data = pd.read_csv(\"{}/output_preprocessing/graph_data/{}_edges_data_{}.csv\".format(self.dir, self.group, self.subgroup))\n",
    "        \n",
    "        node_features = torch.from_numpy(np.log10(nodes_data[\"degree\"].to_numpy()))\n",
    "        node_features = node_features.to(torch.float32)\n",
    "        node_features = torch.reshape(node_features, (-1, 1))\n",
    "\n",
    "        node_labels = torch.from_numpy(nodes_data[\"ionMz\"].to_numpy())\n",
    "        node_labels = node_labels.to(torch.float32)\n",
    "\n",
    "        edge_features = torch.from_numpy(edges_data[\"weight\"].to_numpy())\n",
    "        edges_src = torch.from_numpy(edges_data[\"source\"].to_numpy())\n",
    "        edges_dst = torch.from_numpy(edges_data[\"target\"].to_numpy())\n",
    "\n",
    "        self.graph = dgl.graph(\n",
    "            (edges_src, edges_dst), num_nodes=nodes_data.shape[0]\n",
    "        )\n",
    "        self.graph.ndata[\"feat\"] = node_features\n",
    "        self.graph.ndata[\"label\"] = node_labels\n",
    "        self.graph.edata[\"weight\"] = edge_features\n",
    "\n",
    "        # If your dataset is a node classification dataset, you will need to assign\n",
    "        # masks indicating whether a node belongs to training, validation, and test set.\n",
    "        n_nodes = nodes_data.shape[0]\n",
    "        n_train = int(n_nodes * 0.6)\n",
    "        n_val = int(n_nodes * 0.2)\n",
    "        train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        val_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        train_mask[:n_train] = True\n",
    "        val_mask[n_train : n_train + n_val] = True\n",
    "        test_mask[n_train + n_val :] = True\n",
    "        self.graph.ndata[\"train_mask\"] = train_mask\n",
    "        self.graph.ndata[\"val_mask\"] = val_mask\n",
    "        self.graph.ndata[\"test_mask\"] = test_mask\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.graph\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=6235, num_edges=1629510,\n",
      "      ndata_schemes={'feat': Scheme(shape=(1,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.float32), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}\n",
      "      edata_schemes={'weight': Scheme(shape=(), dtype=torch.float64)})\n",
      "time: 332 ms (started: 2023-05-19 09:45:05 -05:00)\n"
     ]
    }
   ],
   "source": [
    "dataset = CustomDataset(\"g1\", dir, group[0], 1)\n",
    "graph = dataset[0]\n",
    "\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11.6 ms (started: 2023-05-19 09:45:07 -05:00)\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\"\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Variant Graph Auto Encoder\")\n",
    "parser.add_argument(\n",
    "    \"--learning_rate\", type=float, default=0.01, help=\"Initial learning rate.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--epochs\", \"-e\", type=int, default=100, help=\"Number of epochs to train.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--hidden1\",\n",
    "    \"-h1\",\n",
    "    type=int,\n",
    "    default=32,\n",
    "    help=\"Number of units in hidden layer 1.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--hidden2\",\n",
    "    \"-h2\",\n",
    "    type=int,\n",
    "    default=3,\n",
    "    help=\"Number of units in hidden layer 2.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--datasrc\",\n",
    "    \"-s\",\n",
    "    type=str,\n",
    "    default=\"dgl\",\n",
    "    help=\"Dataset download from dgl Dataset or website.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--dataset\", \"-d\", type=str, default=\"cora\", help=\"Dataset string.\"\n",
    ")\n",
    "parser.add_argument(\"--gpu_id\", type=int, default=0, help=\"GPU id to use.\")\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "\n",
    "# check device\n",
    "device = torch.device(\n",
    "    \"cuda:{}\".format(args.gpu_id) if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "# device = \"cpu\"\n",
    "device\n",
    "# roc_means = []\n",
    "# ap_means = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 971 µs (started: 2023-05-19 09:45:11 -05:00)\n"
     ]
    }
   ],
   "source": [
    "def compute_loss_para(adj):\n",
    "    pos_weight = (adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum()\n",
    "    norm = (\n",
    "        adj.shape[0]\n",
    "        * adj.shape[0]\n",
    "        / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)\n",
    "    )\n",
    "    weight_mask = adj.view(-1) == 1\n",
    "    weight_tensor = torch.ones(weight_mask.size(0)).to(device)\n",
    "    weight_tensor[weight_mask] = pos_weight\n",
    "    return weight_tensor, norm\n",
    "\n",
    "\n",
    "def get_acc(adj_rec, adj_label):\n",
    "    labels_all = adj_label.view(-1).long()\n",
    "    preds_all = (adj_rec > 0.5).view(-1).long()\n",
    "    accuracy = (preds_all == labels_all).sum().float() / labels_all.size(0)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def get_scores(edges_pos, edges_neg, adj_rec):\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    adj_rec = adj_rec.cpu()\n",
    "    # Predict on test set of edges\n",
    "    preds = []\n",
    "    for e in edges_pos:\n",
    "        preds.append(sigmoid(adj_rec[e[0], e[1]].item()))\n",
    "\n",
    "    preds_neg = []\n",
    "    for e in edges_neg:\n",
    "        preds_neg.append(sigmoid(adj_rec[e[0], e[1]].data))\n",
    "\n",
    "    preds_all = np.hstack([preds, preds_neg])\n",
    "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
    "    roc_score = roc_auc_score(labels_all, preds_all)\n",
    "    ap_score = average_precision_score(labels_all, preds_all)\n",
    "\n",
    "    return roc_score, ap_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 369 µs (started: 2023-05-18 22:11:39 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=6235, num_edges=1629510,\n",
      "      ndata_schemes={'feat': Scheme(shape=(1,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.float32), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}\n",
      "      edata_schemes={'weight': Scheme(shape=(), dtype=torch.float64)})\n",
      "Total Parameters: 262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A/home/ealvarez/miniconda3/envs/Conda_vgae_3.10/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|█████████████████████████████████████████| 100/100 [00:01<00:00, 61.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=6234, num_edges=4417355,\n",
      "      ndata_schemes={'feat': Scheme(shape=(1,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.float32), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}\n",
      "      edata_schemes={'weight': Scheme(shape=(), dtype=torch.float64)})\n",
      "Total Parameters: 262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A/home/ealvarez/miniconda3/envs/Conda_vgae_3.10/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|█████████████████████████████████████████| 100/100 [00:01<00:00, 84.75it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:08<00:00,  4.47s/it]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:08<00:00,  8.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.96 s (started: 2023-05-19 09:45:17 -05:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get node embeddings\n",
    "\n",
    "# list_embeddings_time = []\n",
    "for dimension in tqdm(dimensions):\n",
    "    # Get embeddings\n",
    "    \"\"\" parser.set_defaults(self_loop=True)\n",
    "    parser.set_defaults(n_hidden=dimension)\n",
    "    parser.set_defaults(n_layers=3)\n",
    "    args = parser.parse_args(\"\") \"\"\"\n",
    "    # print(args)\n",
    "\n",
    "    for i in tqdm(subgroups):\n",
    "        # Read dataset\n",
    "\n",
    "        data = CustomDataset(\"g\".format(i), dir, group[0], i)\n",
    "        graph = data[0]\n",
    "        print(graph)\n",
    "\n",
    "        # Extract node features\n",
    "        feats = graph.ndata.pop(\"feat\").to(device)\n",
    "        in_dim = feats.shape[-1]\n",
    "\n",
    "        # generate input\n",
    "        adj_orig = graph.adj_external().to_dense()\n",
    "\n",
    "        # build test set with 10% positive links\n",
    "        (\n",
    "            train_edge_idx,\n",
    "            val_edges,\n",
    "            val_edges_false,\n",
    "            test_edges,\n",
    "            test_edges_false,\n",
    "        ) = mask_test_edges_dgl(graph, adj_orig)\n",
    "\n",
    "        graph = graph.to(device)\n",
    "\n",
    "        # create train graph\n",
    "        train_edge_idx = torch.tensor(train_edge_idx).to(device)\n",
    "        train_graph = dgl.edge_subgraph(graph, train_edge_idx, relabel_nodes=False)\n",
    "        train_graph = train_graph.to(device)\n",
    "        adj = train_graph.adj_external().to_dense().to(device)\n",
    "\n",
    "        # compute loss parameters\n",
    "        weight_tensor, norm = compute_loss_para(adj)\n",
    "\n",
    "        # create model\n",
    "        vgae_model = model.VGAEModel(in_dim, args.hidden1, args.hidden2)\n",
    "        vgae_model = vgae_model.to(device)\n",
    "\n",
    "        # create training component\n",
    "        optimizer = torch.optim.Adam(vgae_model.parameters(), lr=args.learning_rate)\n",
    "        print(\n",
    "            \"Total Parameters:\",\n",
    "            sum([p.nelement() for p in vgae_model.parameters()]),\n",
    "        )\n",
    "\n",
    "        # create training epoch\n",
    "        for epoch in tqdm(range(args.epochs)):\n",
    "            t = time.time()\n",
    "\n",
    "            # Training and validation using a full graph\n",
    "            vgae_model.train()\n",
    "\n",
    "            logits = vgae_model.forward(graph, feats)\n",
    "\n",
    "            # compute loss\n",
    "            loss = norm * F.binary_cross_entropy(\n",
    "                logits.view(-1), adj.view(-1), weight=weight_tensor\n",
    "            )\n",
    "            kl_divergence = (\n",
    "                0.5\n",
    "                / logits.size(0)\n",
    "                * (\n",
    "                    1\n",
    "                    + 2 * vgae_model.log_std\n",
    "                    - vgae_model.mean**2\n",
    "                    - torch.exp(vgae_model.log_std) ** 2\n",
    "                )\n",
    "                .sum(1)\n",
    "                .mean()\n",
    "            )\n",
    "            loss -= kl_divergence\n",
    "\n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # train_acc = get_acc(logits, adj)\n",
    "\n",
    "            # val_roc, val_ap = get_scores(val_edges, val_edges_false, logits)\n",
    "\n",
    "            # Print out performance\n",
    "            \"\"\" print(\n",
    "                \"Epoch:\",\n",
    "                \"%04d\" % (epoch + 1),\n",
    "                \"train_loss=\",\n",
    "                \"{:.5f}\".format(loss.item()),\n",
    "                \"train_acc=\",\n",
    "                \"{:.5f}\".format(train_acc),\n",
    "                \"val_roc=\",\n",
    "                \"{:.5f}\".format(val_roc),\n",
    "                \"val_ap=\",\n",
    "                \"{:.5f}\".format(val_ap),\n",
    "                \"time=\",\n",
    "                \"{:.5f}\".format(time.time() - t),\n",
    "            ) \"\"\"\n",
    "\n",
    "        \"\"\" test_roc, test_ap = get_scores(test_edges, test_edges_false, logits)\n",
    "        # roc_means.append(test_roc)\n",
    "        # ap_means.append(test_ap)\n",
    "        print(\n",
    "            \"End of training!\",\n",
    "            \"test_roc=\",\n",
    "            \"{:.5f}\".format(test_roc),\n",
    "            \"test_ap=\",\n",
    "            \"{:.5f}\".format(test_ap),\n",
    "        ) \"\"\"\n",
    "\n",
    "        embeds = vgae_model.encoder(graph, feats)\n",
    "        embeds = embeds.cpu().detach()\n",
    "\n",
    "        df_node_embeddings = pd.DataFrame(data=embeds)\n",
    "        df_node_embeddings\n",
    "\n",
    "        # save\n",
    "        df_node_embeddings.to_csv(\"{}/output_{}/node_embeddings/{}_node-embeddings_{}_{}.csv\".format(dir, method, group[0], dimension, i), index=True)\n",
    "        # print(\"Save node embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.135048</td>\n",
       "      <td>-1.033933</td>\n",
       "      <td>-1.376384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.228674</td>\n",
       "      <td>-0.341864</td>\n",
       "      <td>0.494187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.318110</td>\n",
       "      <td>0.570170</td>\n",
       "      <td>0.223981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.009343</td>\n",
       "      <td>-0.040677</td>\n",
       "      <td>0.556957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.421293</td>\n",
       "      <td>1.116310</td>\n",
       "      <td>-0.463141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6230</th>\n",
       "      <td>-0.296726</td>\n",
       "      <td>-0.008166</td>\n",
       "      <td>-0.206550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6231</th>\n",
       "      <td>0.028187</td>\n",
       "      <td>0.066026</td>\n",
       "      <td>-0.165418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6232</th>\n",
       "      <td>-0.249837</td>\n",
       "      <td>-0.082105</td>\n",
       "      <td>0.097760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6233</th>\n",
       "      <td>-0.146366</td>\n",
       "      <td>-0.010577</td>\n",
       "      <td>0.298308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6234</th>\n",
       "      <td>-0.233786</td>\n",
       "      <td>0.103625</td>\n",
       "      <td>0.277366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6235 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2\n",
       "0     0.135048 -1.033933 -1.376384\n",
       "1    -0.228674 -0.341864  0.494187\n",
       "2     0.318110  0.570170  0.223981\n",
       "3    -0.009343 -0.040677  0.556957\n",
       "4    -0.421293  1.116310 -0.463141\n",
       "...        ...       ...       ...\n",
       "6230 -0.296726 -0.008166 -0.206550\n",
       "6231  0.028187  0.066026 -0.165418\n",
       "6232 -0.249837 -0.082105  0.097760\n",
       "6233 -0.146366 -0.010577  0.298308\n",
       "6234 -0.233786  0.103625  0.277366\n",
       "\n",
       "[6235 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 13.4 ms (started: 2023-05-19 09:45:36 -05:00)\n"
     ]
    }
   ],
   "source": [
    "df_node_embeddings = pd.read_csv(\"{}/output_{}/node_embeddings/{}_node-embeddings_{}_{}.csv\".format(dir, method, group[0], 3, 1), index_col=0)\n",
    "df_node_embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
