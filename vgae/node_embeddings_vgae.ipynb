{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "\n",
    "import dgl\n",
    "\n",
    "import model\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from dgl.data import CiteseerGraphDataset, CoraGraphDataset, PubmedGraphDataset\n",
    "# from input_data import load_data\n",
    "\n",
    "import torch\n",
    "from dgl.data import DGLDataset\n",
    "\n",
    "from preprocess import (\n",
    "    mask_test_edges,\n",
    "    mask_test_edges_dgl,\n",
    "    preprocess_graph,\n",
    "    sparse_to_tuple,\n",
    ")\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 161 µs (started: 2023-06-08 19:22:36 -05:00)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/miniconda3/envs/Conda_dgl_3.10/lib/python3.10/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/ealvarez/miniconda3/envs/Conda_dgl_3.10/lib/python3.10/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/ealvarez/miniconda3/envs/Conda_dgl_3.10/lib/python3.10/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.19 s (started: 2023-06-08 19:22:36 -05:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/miniconda3/envs/Conda_dgl_3.10/lib/python3.10/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.67 ms (started: 2023-06-08 19:22:39 -05:00)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/Project/GNN_Filter/GNN_unsupervised\n",
      "Exp:\t\t exp5\n",
      "Method:\t\t vgae\n",
      "Dimension:\t 3\n",
      "Groups id:\t ['WT', 'zwf1^', 'pck1^']\n",
      "Subgroups id:\t {'WT': ['1', '2', '3', '4', '5'], 'zwf1^': ['1', '2', '3'], 'pck1^': ['1', '2']}\n",
      "Option:\t\t dyn\n",
      "Subgroups id:\t {'WT': ['dyn'], 'zwf1^': ['dyn'], 'pck1^': ['dyn']}\n",
      "time: 3.7 ms (started: 2023-06-08 19:22:39 -05:00)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# dir = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "dir = os.path.dirname(os.getcwd())\n",
    "print(dir)\n",
    "\n",
    "# opening JSON file\n",
    "file = open(\"{}/parameters.json\".format(dir))\n",
    "params = json.load(file)\n",
    "\n",
    "exp = params[\"exp\"]\n",
    "print(\"Exp:\\t\\t\", exp)\n",
    "\n",
    "method = \"vgae\"\n",
    "print(\"Method:\\t\\t\", method)\n",
    "\n",
    "dimension = params[\"dimension\"]\n",
    "print(\"Dimension:\\t\", dimension)\n",
    "\n",
    "groups_id = params[\"groups_id\"]\n",
    "print(\"Groups id:\\t\", groups_id)\n",
    "\n",
    "subgroups_id = params[\"subgroups_id\"]\n",
    "print(\"Subgroups id:\\t\", subgroups_id)\n",
    "\n",
    "option = params[\"option\"]\n",
    "print(\"Option:\\t\\t\", option)\n",
    "\n",
    "if option:\n",
    "    for group in groups_id:\n",
    "        subgroups_id[group] = [option]\n",
    "    print(\"Subgroups id:\\t\", subgroups_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.33 ms (started: 2023-06-08 19:22:39 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# custom dataset\n",
    "\n",
    "class CustomDataset(DGLDataset):\n",
    "    def __init__(self, name, nodes_data, edges_data):\n",
    "        self.dir = dir\n",
    "        self.nodes_data = nodes_data\n",
    "        self.edges_data = edges_data\n",
    "        super().__init__(name=name)\n",
    "       \n",
    "    def process(self):\n",
    "        # node_features = torch.from_numpy(self.nodes_data[\"degree\"].to_numpy())\n",
    "        node_features = torch.from_numpy(np.log10(self.nodes_data[\"degree\"].to_numpy()))\n",
    "        node_features = node_features.to(torch.float32)\n",
    "        node_features = torch.reshape(node_features, (-1, 1))\n",
    "\n",
    "        # node_labels = torch.from_numpy(self.nodes_data[\"id\"].to_numpy())\n",
    "        # node_labels = node_labels.to(torch.float32)\n",
    "\n",
    "        edge_features = torch.from_numpy(self.edges_data[\"weight\"].to_numpy())\n",
    "        edges_src = torch.from_numpy(self.edges_data[\"source\"].to_numpy())\n",
    "        edges_dst = torch.from_numpy(self.edges_data[\"target\"].to_numpy())\n",
    "\n",
    "        self.graph = dgl.graph(\n",
    "            (edges_src, edges_dst), num_nodes=self.nodes_data.shape[0]\n",
    "        )\n",
    "        self.graph.ndata[\"feat\"] = node_features\n",
    "        # self.graph.ndata[\"label\"] = node_labels\n",
    "        self.graph.edata[\"weight\"] = edge_features\n",
    "\n",
    "        # If your dataset is a node classification dataset, you will need to assign\n",
    "        # masks indicating whether a node belongs to training, validation, and test set.\n",
    "        n_nodes = self.nodes_data.shape[0]\n",
    "        n_train = int(n_nodes * 0.6)\n",
    "        n_val = int(n_nodes * 0.2)\n",
    "        train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        val_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        train_mask[:n_train] = True\n",
    "        val_mask[n_train : n_train + n_val] = True\n",
    "        test_mask[n_train + n_val :] = True\n",
    "        self.graph.ndata[\"train_mask\"] = train_mask\n",
    "        self.graph.ndata[\"val_mask\"] = val_mask\n",
    "        self.graph.ndata[\"test_mask\"] = test_mask\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.graph\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=31150, num_edges=12257101,\n",
      "      ndata_schemes={'feat': Scheme(shape=(1,), dtype=torch.float32), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}\n",
      "      edata_schemes={'weight': Scheme(shape=(), dtype=torch.float64)})\n",
      "time: 2.45 s (started: 2023-06-08 19:22:40 -05:00)\n"
     ]
    }
   ],
   "source": [
    "nodes_data = pd.read_csv(\"{}/output/{}/preprocessing/graphs_data/nodes_data_{}_{}.csv\".format(dir, exp, groups_id[0], subgroups_id[groups_id[0]][0]))\n",
    "edges_data = pd.read_csv(\"{}/output/{}/preprocessing/graphs_data/edges_data_{}_{}.csv\".format(dir, exp, groups_id[0], subgroups_id[groups_id[0]][0]))\n",
    "\n",
    "dataset = CustomDataset(\"g1\", nodes_data, edges_data)\n",
    "graph = dataset[0]\n",
    "\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.12 ms (started: 2023-06-08 19:22:42 -05:00)\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\"\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Variant Graph Auto Encoder\")\n",
    "parser.add_argument(\n",
    "    \"--learning_rate\", type=float, default=1e-3, help=\"Initial learning rate.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--epochs\", \"-e\", type=int, default=300, help=\"Number of epochs to train.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--hidden1\",\n",
    "    \"-h1\",\n",
    "    type=int,\n",
    "    default=32,\n",
    "    help=\"Number of units in hidden layer 1.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--hidden2\",\n",
    "    \"-h2\",\n",
    "    type=int,\n",
    "    default=3,\n",
    "    help=\"Number of units in hidden layer 2.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--datasrc\",\n",
    "    \"-s\",\n",
    "    type=str,\n",
    "    default=\"dgl\",\n",
    "    help=\"Dataset download from dgl Dataset or website.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--dataset\", \"-d\", type=str, default=\"cora\", help=\"Dataset string.\"\n",
    ")\n",
    "parser.add_argument(\"--gpu_id\", type=int, default=0, help=\"GPU id to use.\")\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "\n",
    "# check device\n",
    "device = torch.device(\n",
    "    \"cuda:{}\".format(args.gpu_id) if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "# device = \"cpu\"\n",
    "device\n",
    "# roc_means = []\n",
    "# ap_means = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.62 ms (started: 2023-06-08 19:22:42 -05:00)\n"
     ]
    }
   ],
   "source": [
    "def compute_loss_para(adj):\n",
    "    pos_weight = (adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum()\n",
    "    norm = (\n",
    "        adj.shape[0]\n",
    "        * adj.shape[0]\n",
    "        / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)\n",
    "    )\n",
    "    weight_mask = adj.view(-1) == 1\n",
    "    weight_tensor = torch.ones(weight_mask.size(0)).to(device)\n",
    "    weight_tensor[weight_mask] = pos_weight\n",
    "    return weight_tensor, norm\n",
    "\n",
    "\n",
    "def get_acc(adj_rec, adj_label):\n",
    "    labels_all = adj_label.view(-1).long()\n",
    "    preds_all = (adj_rec > 0.5).view(-1).long()\n",
    "    accuracy = (preds_all == labels_all).sum().float() / labels_all.size(0)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def get_scores(edges_pos, edges_neg, adj_rec):\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    adj_rec = adj_rec.cpu()\n",
    "    # Predict on test set of edges\n",
    "    preds = []\n",
    "    for e in edges_pos:\n",
    "        preds.append(sigmoid(adj_rec[e[0], e[1]].item()))\n",
    "\n",
    "    preds_neg = []\n",
    "    for e in edges_neg:\n",
    "        preds_neg.append(sigmoid(adj_rec[e[0], e[1]].data))\n",
    "\n",
    "    preds_all = np.hstack([preds, preds_neg])\n",
    "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
    "    roc_score = roc_auc_score(labels_all, preds_all)\n",
    "    ap_score = average_precision_score(labels_all, preds_all)\n",
    "\n",
    "    return roc_score, ap_score\n",
    "\n",
    "def train_vgae(graph, args, method, group, subgroup):\n",
    "    # extract node features\n",
    "    feats = graph.ndata.pop(\"feat\").to(device)\n",
    "    in_dim = feats.shape[-1]\n",
    "\n",
    "    # generate input\n",
    "    adj_orig = graph.adj_external().to_dense()\n",
    "\n",
    "    # build test set with 10% positive links\n",
    "    (\n",
    "        train_edge_idx,\n",
    "        val_edges,\n",
    "        val_edges_false,\n",
    "        test_edges,\n",
    "        test_edges_false,\n",
    "    ) = mask_test_edges_dgl(graph, adj_orig)\n",
    "\n",
    "    graph = graph.to(device)\n",
    "\n",
    "    # create train graph\n",
    "    train_edge_idx = torch.tensor(train_edge_idx).to(device)\n",
    "    train_graph = dgl.edge_subgraph(graph, train_edge_idx, relabel_nodes=False)\n",
    "    train_graph = train_graph.to(device)\n",
    "    adj = train_graph.adj_external().to_dense().to(device)\n",
    "\n",
    "    # compute loss parameters\n",
    "    weight_tensor, norm = compute_loss_para(adj)\n",
    "\n",
    "    # create model\n",
    "    vgae_model = model.VGAEModel(in_dim, args.hidden1, args.hidden2)\n",
    "    vgae_model = vgae_model.to(device)\n",
    "\n",
    "    # create training component\n",
    "    optimizer = torch.optim.Adam(vgae_model.parameters(), lr=args.learning_rate)\n",
    "    print(\n",
    "        \"Total Parameters:\",\n",
    "        sum([p.nelement() for p in vgae_model.parameters()]),\n",
    "    )\n",
    "\n",
    "    # create training epoch\n",
    "    for epoch in tqdm(range(args.epochs)):\n",
    "        t = time.time()\n",
    "\n",
    "        # Training and validation using a full graph\n",
    "        vgae_model.train()\n",
    "\n",
    "        logits = vgae_model.forward(graph, feats)\n",
    "\n",
    "        # compute loss\n",
    "        loss = norm * F.binary_cross_entropy(\n",
    "            logits.view(-1), adj.view(-1), weight=weight_tensor\n",
    "        )\n",
    "        kl_divergence = (\n",
    "            0.5\n",
    "            / logits.size(0)\n",
    "            * (\n",
    "                1\n",
    "                + 2 * vgae_model.log_std\n",
    "                - vgae_model.mean**2\n",
    "                - torch.exp(vgae_model.log_std) ** 2\n",
    "            )\n",
    "            .sum(1)\n",
    "            .mean()\n",
    "        )\n",
    "        loss -= kl_divergence\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # train_acc = get_acc(logits, adj)\n",
    "\n",
    "        # val_roc, val_ap = get_scores(val_edges, val_edges_false, logits)\n",
    "\n",
    "        # Print out performance\n",
    "        \"\"\" print(\n",
    "            \"Epoch:\",\n",
    "            \"%04d\" % (epoch + 1),\n",
    "            \"train_loss=\",\n",
    "            \"{:.5f}\".format(loss.item()),\n",
    "            \"train_acc=\",\n",
    "            \"{:.5f}\".format(train_acc),\n",
    "            \"val_roc=\",\n",
    "            \"{:.5f}\".format(val_roc),\n",
    "            \"val_ap=\",\n",
    "            \"{:.5f}\".format(val_ap),\n",
    "            \"time=\",\n",
    "            \"{:.5f}\".format(time.time() - t),\n",
    "        ) \"\"\"\n",
    "\n",
    "    \"\"\" test_roc, test_ap = get_scores(test_edges, test_edges_false, logits)\n",
    "    # roc_means.append(test_roc)\n",
    "    # ap_means.append(test_ap)\n",
    "    print(\n",
    "        \"End of training!\",\n",
    "        \"test_roc=\",\n",
    "        \"{:.5f}\".format(test_roc),\n",
    "        \"test_ap=\",\n",
    "        \"{:.5f}\".format(test_ap),\n",
    "    ) \"\"\"\n",
    "\n",
    "    embeds = vgae_model.encoder(graph, feats)\n",
    "    embeds = embeds.cpu().detach()\n",
    "\n",
    "    df_node_embeddings = pd.DataFrame(data=embeds)\n",
    "    df_node_embeddings\n",
    "\n",
    "    # save\n",
    "    df_node_embeddings.to_csv(\"{}/output/{}/node_embeddings/node-embeddings_{}_{}_{}.csv\".format(dir, exp, method, group, subgroup), index=True)\n",
    "    # print(\"Save node embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 404 µs (started: 2023-06-08 19:22:42 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:13<?, ?it/s]\n",
      "  0%|          | 0/3 [00:13<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 3.62 GiB (GPU 0; 10.75 GiB total capacity; 428.12 MiB already allocated; 2.94 GiB free; 430.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m graph \u001b[39m=\u001b[39m data[\u001b[39m0\u001b[39m]\n\u001b[1;32m     13\u001b[0m \u001b[39m# train\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m train_vgae(graph, args, method, group, subgroup)\n",
      "Cell \u001b[0;32mIn[10], line 65\u001b[0m, in \u001b[0;36mtrain_vgae\u001b[0;34m(graph, args, method, group, subgroup)\u001b[0m\n\u001b[1;32m     63\u001b[0m train_graph \u001b[39m=\u001b[39m dgl\u001b[39m.\u001b[39medge_subgraph(graph, train_edge_idx, relabel_nodes\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     64\u001b[0m train_graph \u001b[39m=\u001b[39m train_graph\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 65\u001b[0m adj \u001b[39m=\u001b[39m train_graph\u001b[39m.\u001b[39;49madj_external()\u001b[39m.\u001b[39;49mto_dense()\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m     67\u001b[0m \u001b[39m# compute loss parameters\u001b[39;00m\n\u001b[1;32m     68\u001b[0m weight_tensor, norm \u001b[39m=\u001b[39m compute_loss_para(adj)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 3.62 GiB (GPU 0; 10.75 GiB total capacity; 428.12 MiB already allocated; 2.94 GiB free; 430.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 13.8 s (started: 2023-06-08 19:22:42 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# get node embeddings\n",
    "\n",
    "for group in tqdm(groups_id):\n",
    "    for subgroup in tqdm(subgroups_id[group]):\n",
    "        nodes_data = pd.read_csv(\"{}/output/{}/preprocessing/graphs_data/nodes_data_{}_{}.csv\".format(dir, exp, group, subgroup))\n",
    "        edges_data = pd.read_csv(\"{}/output/{}/preprocessing/graphs_data/edges_data_{}_{}.csv\".format(dir, exp, group, subgroup))\n",
    "\n",
    "        # read dataset\n",
    "        # data = load_data(args)\n",
    "        data = CustomDataset(\"g_{}_{}\".format(group, subgroup), nodes_data, edges_data)\n",
    "        graph = data[0]\n",
    "\n",
    "        # train\n",
    "        train_vgae(graph, args, method, group, subgroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.253404</td>\n",
       "      <td>0.090255</td>\n",
       "      <td>-0.488362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.288619</td>\n",
       "      <td>0.063895</td>\n",
       "      <td>0.204877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.191579</td>\n",
       "      <td>1.008257</td>\n",
       "      <td>1.362132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.368521</td>\n",
       "      <td>-0.067463</td>\n",
       "      <td>0.107074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.384290</td>\n",
       "      <td>1.547227</td>\n",
       "      <td>0.986131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0 -1.253404  0.090255 -0.488362\n",
       "1  1.288619  0.063895  0.204877\n",
       "2 -1.191579  1.008257  1.362132\n",
       "3 -0.368521 -0.067463  0.107074\n",
       "4  0.384290  1.547227  0.986131"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.9 ms (started: 2023-06-08 19:22:06 -05:00)\n"
     ]
    }
   ],
   "source": [
    "df_node_embeddings = pd.read_csv(\"{}/output/{}/node_embeddings/node-embeddings_{}_{}_{}.csv\".format(dir, exp, method, groups_id[0], \n",
    "                                                                                                    subgroups_id[groups_id[0]][0]), index_col=0)\n",
    "df_node_embeddings.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
