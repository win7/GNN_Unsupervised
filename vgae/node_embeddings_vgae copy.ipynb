{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.61 ms (started: 2023-05-21 14:08:08 -05:00)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "\n",
    "import dgl\n",
    "\n",
    "import model\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from dgl.data import CiteseerGraphDataset, CoraGraphDataset, PubmedGraphDataset\n",
    "# from input_data import load_data\n",
    "\n",
    "import torch\n",
    "from dgl.data import DGLDataset\n",
    "\n",
    "from preprocess import (\n",
    "    mask_test_edges,\n",
    "    mask_test_edges_dgl,\n",
    "    preprocess_graph,\n",
    "    sparse_to_tuple,\n",
    ")\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "time: 1 ms (started: 2023-05-21 14:08:08 -05:00)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 726 µs (started: 2023-05-21 14:08:08 -05:00)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11.1 ms (started: 2023-05-21 14:08:09 -05:00)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/Project/GNN_Filter\n",
      "Method:\t\t vgae\n",
      "Group:\t\t ['pck1^', 2]\n",
      "Subgroup:\t ['1', '2']\n",
      "Dimensions:\t [3]\n",
      "time: 2.73 ms (started: 2023-05-21 14:08:09 -05:00)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "dir = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "print(dir)\n",
    "\n",
    "# Opening JSON file\n",
    "file = open(\"{}/GNN_unsupervised/parameters.json\".format(dir))\n",
    "params = json.load(file)\n",
    "\n",
    "method = params[\"method\"][params[\"method_idx\"]]\n",
    "print(\"Method:\\t\\t\", method)\n",
    "\n",
    "group = params[\"group\"][params[\"group_idx\"]]\n",
    "print(\"Group:\\t\\t\", group)\n",
    "\n",
    "subgroups = [str(k + 1) for k in range(group[1])]\n",
    "print(\"Subgroup:\\t\", subgroups)\n",
    "\n",
    "dimensions = params[\"dimensions\"]\n",
    "print(\"Dimensions:\\t\", dimensions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.79 ms (started: 2023-05-21 14:08:09 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Custom dataset\n",
    "\n",
    "class CustomDataset(DGLDataset):\n",
    "    def __init__(self, name, dir, group, subgroup):\n",
    "        self.dir = dir\n",
    "        self.group = group\n",
    "        self.subgroup = subgroup\n",
    "        super().__init__(name=name)\n",
    "       \n",
    "    def process(self):\n",
    "        nodes_data = pd.read_csv(\"{}/output_preprocessing/graph_data/{}_nodes_data_{}.csv\".format(self.dir, self.group, self.subgroup))\n",
    "        edges_data = pd.read_csv(\"{}/output_preprocessing/graph_data/{}_edges_data_{}.csv\".format(self.dir, self.group, self.subgroup))\n",
    "        \n",
    "        node_features = torch.from_numpy(np.log10(nodes_data[\"degree\"].to_numpy()))\n",
    "        node_features = node_features.to(torch.float32)\n",
    "        node_features = torch.reshape(node_features, (-1, 1))\n",
    "\n",
    "        node_labels = torch.from_numpy(nodes_data[\"ionMz\"].to_numpy())\n",
    "        node_labels = node_labels.to(torch.float32)\n",
    "\n",
    "        edge_features = torch.from_numpy(edges_data[\"weight\"].to_numpy())\n",
    "        edges_src = torch.from_numpy(edges_data[\"source\"].to_numpy())\n",
    "        edges_dst = torch.from_numpy(edges_data[\"target\"].to_numpy())\n",
    "\n",
    "        self.graph = dgl.graph(\n",
    "            (edges_src, edges_dst), num_nodes=nodes_data.shape[0]\n",
    "        )\n",
    "        self.graph.ndata[\"feat\"] = node_features\n",
    "        self.graph.ndata[\"label\"] = node_labels\n",
    "        self.graph.edata[\"weight\"] = edge_features\n",
    "\n",
    "        # If your dataset is a node classification dataset, you will need to assign\n",
    "        # masks indicating whether a node belongs to training, validation, and test set.\n",
    "        n_nodes = nodes_data.shape[0]\n",
    "        n_train = int(n_nodes * 0.6)\n",
    "        n_val = int(n_nodes * 0.2)\n",
    "        train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        val_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        train_mask[:n_train] = True\n",
    "        val_mask[n_train : n_train + n_val] = True\n",
    "        test_mask[n_train + n_val :] = True\n",
    "        self.graph.ndata[\"train_mask\"] = train_mask\n",
    "        self.graph.ndata[\"val_mask\"] = val_mask\n",
    "        self.graph.ndata[\"test_mask\"] = test_mask\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.graph\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=6235, num_edges=1629510,\n",
      "      ndata_schemes={'feat': Scheme(shape=(1,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.float32), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}\n",
      "      edata_schemes={'weight': Scheme(shape=(), dtype=torch.float64)})\n",
      "time: 436 ms (started: 2023-05-21 14:08:09 -05:00)\n"
     ]
    }
   ],
   "source": [
    "dataset = CustomDataset(\"g1\", dir, group[0], 1)\n",
    "graph = dataset[0]\n",
    "\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.57 ms (started: 2023-05-21 14:08:09 -05:00)\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\"\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Variant Graph Auto Encoder\")\n",
    "parser.add_argument(\n",
    "    \"--learning_rate\", type=float, default=1e-3, help=\"Initial learning rate.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--epochs\", \"-e\", type=int, default=300, help=\"Number of epochs to train.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--hidden1\",\n",
    "    \"-h1\",\n",
    "    type=int,\n",
    "    default=32,\n",
    "    help=\"Number of units in hidden layer 1.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--hidden2\",\n",
    "    \"-h2\",\n",
    "    type=int,\n",
    "    default=3,\n",
    "    help=\"Number of units in hidden layer 2.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--datasrc\",\n",
    "    \"-s\",\n",
    "    type=str,\n",
    "    default=\"dgl\",\n",
    "    help=\"Dataset download from dgl Dataset or website.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--dataset\", \"-d\", type=str, default=\"cora\", help=\"Dataset string.\"\n",
    ")\n",
    "parser.add_argument(\"--gpu_id\", type=int, default=0, help=\"GPU id to use.\")\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "\n",
    "# check device\n",
    "device = torch.device(\n",
    "    \"cuda:{}\".format(args.gpu_id) if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "# device = \"cpu\"\n",
    "device\n",
    "# roc_means = []\n",
    "# ap_means = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.32 ms (started: 2023-05-21 14:08:09 -05:00)\n"
     ]
    }
   ],
   "source": [
    "def compute_loss_para(adj):\n",
    "    pos_weight = (adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum()\n",
    "    norm = (\n",
    "        adj.shape[0]\n",
    "        * adj.shape[0]\n",
    "        / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)\n",
    "    )\n",
    "    weight_mask = adj.view(-1) == 1\n",
    "    weight_tensor = torch.ones(weight_mask.size(0)).to(device)\n",
    "    weight_tensor[weight_mask] = pos_weight\n",
    "    return weight_tensor, norm\n",
    "\n",
    "\n",
    "def get_acc(adj_rec, adj_label):\n",
    "    labels_all = adj_label.view(-1).long()\n",
    "    preds_all = (adj_rec > 0.5).view(-1).long()\n",
    "    accuracy = (preds_all == labels_all).sum().float() / labels_all.size(0)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def get_scores(edges_pos, edges_neg, adj_rec):\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    adj_rec = adj_rec.cpu()\n",
    "    # Predict on test set of edges\n",
    "    preds = []\n",
    "    for e in edges_pos:\n",
    "        preds.append(sigmoid(adj_rec[e[0], e[1]].item()))\n",
    "\n",
    "    preds_neg = []\n",
    "    for e in edges_neg:\n",
    "        preds_neg.append(sigmoid(adj_rec[e[0], e[1]].data))\n",
    "\n",
    "    preds_all = np.hstack([preds, preds_neg])\n",
    "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
    "    roc_score = roc_auc_score(labels_all, preds_all)\n",
    "    ap_score = average_precision_score(labels_all, preds_all)\n",
    "\n",
    "    return roc_score, ap_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 398 µs (started: 2023-05-21 14:08:10 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=6235, num_edges=1629510,\n",
      "      ndata_schemes={'feat': Scheme(shape=(1,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.float32), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}\n",
      "      edata_schemes={'weight': Scheme(shape=(), dtype=torch.float64)})\n",
      "Total Parameters: 262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A/home/ealvarez/miniconda3/envs/Conda_vgae_3.10/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|█████████████████████████████████████████| 300/300 [00:04<00:00, 73.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=6234, num_edges=4417355,\n",
      "      ndata_schemes={'feat': Scheme(shape=(1,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.float32), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}\n",
      "      edata_schemes={'weight': Scheme(shape=(), dtype=torch.float64)})\n",
      "Total Parameters: 262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A/home/ealvarez/miniconda3/envs/Conda_vgae_3.10/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|█████████████████████████████████████████| 300/300 [00:04<00:00, 66.04it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:13<00:00,  6.56s/it]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:13<00:00, 13.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 13.1 s (started: 2023-05-21 14:08:10 -05:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get node embeddings\n",
    "\n",
    "# list_embeddings_time = []\n",
    "for dimension in tqdm(dimensions):\n",
    "    # Get embeddings\n",
    "    \"\"\" parser.set_defaults(self_loop=True)\n",
    "    parser.set_defaults(n_hidden=dimension)\n",
    "    parser.set_defaults(n_layers=3)\n",
    "    args = parser.parse_args(\"\") \"\"\"\n",
    "    # print(args)\n",
    "\n",
    "    for i in tqdm(subgroups):\n",
    "        # Read dataset\n",
    "\n",
    "        data = CustomDataset(\"g\".format(i), dir, group[0], i)\n",
    "        graph = data[0]\n",
    "        print(graph)\n",
    "\n",
    "        # Extract node features\n",
    "        feats = graph.ndata.pop(\"feat\").to(device)\n",
    "        in_dim = feats.shape[-1]\n",
    "\n",
    "        # generate input\n",
    "        adj_orig = graph.adj_external().to_dense()\n",
    "\n",
    "        # build test set with 10% positive links\n",
    "        (\n",
    "            train_edge_idx,\n",
    "            val_edges,\n",
    "            val_edges_false,\n",
    "            test_edges,\n",
    "            test_edges_false,\n",
    "        ) = mask_test_edges_dgl(graph, adj_orig)\n",
    "\n",
    "        graph = graph.to(device)\n",
    "\n",
    "        # create train graph\n",
    "        train_edge_idx = torch.tensor(train_edge_idx).to(device)\n",
    "        train_graph = dgl.edge_subgraph(graph, train_edge_idx, relabel_nodes=False)\n",
    "        train_graph = train_graph.to(device)\n",
    "        adj = train_graph.adj_external().to_dense().to(device)\n",
    "\n",
    "        # compute loss parameters\n",
    "        weight_tensor, norm = compute_loss_para(adj)\n",
    "\n",
    "        # create model\n",
    "        vgae_model = model.VGAEModel(in_dim, args.hidden1, args.hidden2)\n",
    "        vgae_model = vgae_model.to(device)\n",
    "\n",
    "        # create training component\n",
    "        optimizer = torch.optim.Adam(vgae_model.parameters(), lr=args.learning_rate)\n",
    "        print(\n",
    "            \"Total Parameters:\",\n",
    "            sum([p.nelement() for p in vgae_model.parameters()]),\n",
    "        )\n",
    "\n",
    "        # create training epoch\n",
    "        for epoch in tqdm(range(args.epochs)):\n",
    "            t = time.time()\n",
    "\n",
    "            # Training and validation using a full graph\n",
    "            vgae_model.train()\n",
    "\n",
    "            logits = vgae_model.forward(graph, feats)\n",
    "\n",
    "            # compute loss\n",
    "            loss = norm * F.binary_cross_entropy(\n",
    "                logits.view(-1), adj.view(-1), weight=weight_tensor\n",
    "            )\n",
    "            kl_divergence = (\n",
    "                0.5\n",
    "                / logits.size(0)\n",
    "                * (\n",
    "                    1\n",
    "                    + 2 * vgae_model.log_std\n",
    "                    - vgae_model.mean**2\n",
    "                    - torch.exp(vgae_model.log_std) ** 2\n",
    "                )\n",
    "                .sum(1)\n",
    "                .mean()\n",
    "            )\n",
    "            loss -= kl_divergence\n",
    "\n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # train_acc = get_acc(logits, adj)\n",
    "\n",
    "            # val_roc, val_ap = get_scores(val_edges, val_edges_false, logits)\n",
    "\n",
    "            # Print out performance\n",
    "            \"\"\" print(\n",
    "                \"Epoch:\",\n",
    "                \"%04d\" % (epoch + 1),\n",
    "                \"train_loss=\",\n",
    "                \"{:.5f}\".format(loss.item()),\n",
    "                \"train_acc=\",\n",
    "                \"{:.5f}\".format(train_acc),\n",
    "                \"val_roc=\",\n",
    "                \"{:.5f}\".format(val_roc),\n",
    "                \"val_ap=\",\n",
    "                \"{:.5f}\".format(val_ap),\n",
    "                \"time=\",\n",
    "                \"{:.5f}\".format(time.time() - t),\n",
    "            ) \"\"\"\n",
    "\n",
    "        \"\"\" test_roc, test_ap = get_scores(test_edges, test_edges_false, logits)\n",
    "        # roc_means.append(test_roc)\n",
    "        # ap_means.append(test_ap)\n",
    "        print(\n",
    "            \"End of training!\",\n",
    "            \"test_roc=\",\n",
    "            \"{:.5f}\".format(test_roc),\n",
    "            \"test_ap=\",\n",
    "            \"{:.5f}\".format(test_ap),\n",
    "        ) \"\"\"\n",
    "\n",
    "        embeds = vgae_model.encoder(graph, feats)\n",
    "        embeds = embeds.cpu().detach()\n",
    "\n",
    "        df_node_embeddings = pd.DataFrame(data=embeds)\n",
    "        df_node_embeddings\n",
    "\n",
    "        # save\n",
    "        df_node_embeddings.to_csv(\"{}/output_{}/node_embeddings/{}_node-embeddings_{}_{}.csv\".format(dir, method, group[0], dimension, i), index=True)\n",
    "        # print(\"Save node embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.616567</td>\n",
       "      <td>0.178752</td>\n",
       "      <td>-1.169767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.229846</td>\n",
       "      <td>0.699896</td>\n",
       "      <td>-1.946833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.503601</td>\n",
       "      <td>0.055923</td>\n",
       "      <td>0.242394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.757226</td>\n",
       "      <td>1.169059</td>\n",
       "      <td>1.004435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.234018</td>\n",
       "      <td>0.296189</td>\n",
       "      <td>-0.891795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6230</th>\n",
       "      <td>0.102826</td>\n",
       "      <td>-0.306076</td>\n",
       "      <td>0.941086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6231</th>\n",
       "      <td>-0.199630</td>\n",
       "      <td>-0.179870</td>\n",
       "      <td>0.012245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6232</th>\n",
       "      <td>-0.216606</td>\n",
       "      <td>-0.257275</td>\n",
       "      <td>0.007844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6233</th>\n",
       "      <td>-0.127246</td>\n",
       "      <td>-0.697260</td>\n",
       "      <td>-0.388276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6234</th>\n",
       "      <td>-0.661647</td>\n",
       "      <td>-0.518619</td>\n",
       "      <td>-0.452863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6235 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2\n",
       "0     1.616567  0.178752 -1.169767\n",
       "1     0.229846  0.699896 -1.946833\n",
       "2     0.503601  0.055923  0.242394\n",
       "3     0.757226  1.169059  1.004435\n",
       "4    -0.234018  0.296189 -0.891795\n",
       "...        ...       ...       ...\n",
       "6230  0.102826 -0.306076  0.941086\n",
       "6231 -0.199630 -0.179870  0.012245\n",
       "6232 -0.216606 -0.257275  0.007844\n",
       "6233 -0.127246 -0.697260 -0.388276\n",
       "6234 -0.661647 -0.518619 -0.452863\n",
       "\n",
       "[6235 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12 ms (started: 2023-05-21 14:08:23 -05:00)\n"
     ]
    }
   ],
   "source": [
    "df_node_embeddings = pd.read_csv(\"{}/output_{}/node_embeddings/{}_node-embeddings_{}_{}.csv\".format(dir, method, group[0], 3, 1), index_col=0)\n",
    "df_node_embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
