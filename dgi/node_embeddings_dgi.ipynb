{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "import argparse, time\n",
    "\n",
    "import dgl\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgi import Classifier, DGI\n",
    "from dgl import DGLGraph\n",
    "from dgl.data import load_data, register_data_args, DGLDataset\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 174 µs (started: 2023-06-01 12:56:57 -05:00)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/miniconda3/envs/Conda_dgl_3.10/lib/python3.10/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/ealvarez/miniconda3/envs/Conda_dgl_3.10/lib/python3.10/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/ealvarez/miniconda3/envs/Conda_dgl_3.10/lib/python3.10/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/ealvarez/miniconda3/envs/Conda_dgl_3.10/lib/python3.10/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.8 s (started: 2023-06-01 12:56:57 -05:00)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.39 ms (started: 2023-06-01 12:57:01 -05:00)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.18 ms (started: 2023-06-01 12:57:01 -05:00)\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, features, labels, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/Project/GNN_Filter/GNN_unsupervised\n",
      "Method:\t\t dgi\n",
      "Dimension:\t 3\n",
      "Groups id:\t ['WT', 'zwf1^', 'pck1^']\n",
      "Subgroups id:\t [['1', '2', '3', '4', '5'], ['1', '2', '3'], ['1', '2']]\n",
      "time: 1.25 ms (started: 2023-06-01 12:57:01 -05:00)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# dir = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "dir = os.path.dirname(os.getcwd())\n",
    "print(dir)\n",
    "\n",
    "# opening JSON file\n",
    "file = open(\"{}/parameters.json\".format(dir))\n",
    "params = json.load(file)\n",
    "\n",
    "method = \"dgi\"\n",
    "print(\"Method:\\t\\t\", method)\n",
    "\n",
    "dimensions = params[\"dimensions\"]\n",
    "dimension = dimensions[0]\n",
    "print(\"Dimension:\\t\", dimension)\n",
    "\n",
    "groups_id = params[\"groups_id\"]\n",
    "print(\"Groups id:\\t\", groups_id)\n",
    "\n",
    "subgroups_id = params[\"subgroups_id\"]\n",
    "print(\"Subgroups id:\\t\", subgroups_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.45 ms (started: 2023-06-01 12:57:01 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# custom dataset\n",
    "\n",
    "class CustomDataset(DGLDataset):\n",
    "    def __init__(self, name, nodes_data, edges_data):\n",
    "        self.dir = dir\n",
    "        self.nodes_data = nodes_data\n",
    "        self.edges_data = edges_data\n",
    "        super().__init__(name=name)\n",
    "       \n",
    "    def process(self):\n",
    "        # nodes_data = pd.read_csv(\"{}/output_preprocessing/graph_data/{}_nodes_data_{}.csv\".format(self.dir, self.group, self.subgroup))\n",
    "        # edges_data = pd.read_csv(\"{}/output_preprocessing/graph_data/{}_edges_data_{}.csv\".format(self.dir, self.group, self.subgroup))\n",
    "        \n",
    "        node_features = torch.from_numpy(self.nodes_data[\"degree\"].to_numpy())\n",
    "        node_features = node_features.to(torch.float32)\n",
    "        node_features = torch.reshape(node_features, (-1, 1))\n",
    "\n",
    "        node_labels = torch.from_numpy(self.nodes_data[\"id\"].to_numpy())\n",
    "        node_labels = node_labels.to(torch.float32)\n",
    "\n",
    "        edge_features = torch.from_numpy(self.edges_data[\"weight\"].to_numpy())\n",
    "        edges_src = torch.from_numpy(self.edges_data[\"source\"].to_numpy())\n",
    "        edges_dst = torch.from_numpy(self.edges_data[\"target\"].to_numpy())\n",
    "\n",
    "        self.graph = dgl.graph(\n",
    "            (edges_src, edges_dst), num_nodes=self.nodes_data.shape[0]\n",
    "        )\n",
    "        self.graph.ndata[\"feat\"] = node_features\n",
    "        self.graph.ndata[\"label\"] = node_labels\n",
    "        self.graph.edata[\"weight\"] = edge_features\n",
    "\n",
    "        # If your dataset is a node classification dataset, you will need to assign\n",
    "        # masks indicating whether a node belongs to training, validation, and test set.\n",
    "        n_nodes = self.nodes_data.shape[0]\n",
    "        n_train = int(n_nodes * 0.6)\n",
    "        n_val = int(n_nodes * 0.2)\n",
    "        train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        val_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        train_mask[:n_train] = True\n",
    "        val_mask[n_train : n_train + n_val] = True\n",
    "        test_mask[n_train + n_val :] = True\n",
    "        self.graph.ndata[\"train_mask\"] = train_mask\n",
    "        self.graph.ndata[\"val_mask\"] = val_mask\n",
    "        self.graph.ndata[\"test_mask\"] = test_mask\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.graph\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "def train_dgi(graph, args, method, dimension, group, subgroup):\n",
    "    features = torch.FloatTensor(np.log10(graph.ndata[\"feat\"]))\n",
    "    # print(features.shape)\n",
    "    # labels = torch.LongTensor(graph.ndata[\"label\"])\n",
    "    if hasattr(torch, \"BoolTensor\"):\n",
    "        train_mask = torch.BoolTensor(graph.ndata[\"train_mask\"])\n",
    "        val_mask = torch.BoolTensor(graph.ndata[\"val_mask\"])\n",
    "        test_mask = torch.BoolTensor(graph.ndata[\"test_mask\"])\n",
    "    else:\n",
    "        train_mask = torch.ByteTensor(graph.ndata[\"train_mask\"])\n",
    "        val_mask = torch.ByteTensor(graph.ndata[\"val_mask\"])\n",
    "        test_mask = torch.ByteTensor(graph.ndata[\"test_mask\"])\n",
    "    in_feats = features.shape[1]\n",
    "    # n_classes = data.num_classes\n",
    "    n_edges = graph.num_edges()\n",
    "\n",
    "    if args.gpu < 0:\n",
    "        cuda = False\n",
    "    else:\n",
    "        cuda = True\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "        features = features.cuda()\n",
    "        # labels = labels.cuda()\n",
    "        train_mask = train_mask.cuda()\n",
    "        val_mask = val_mask.cuda()\n",
    "        test_mask = test_mask.cuda()\n",
    "\n",
    "    # add self loop\n",
    "    if args.self_loop:\n",
    "        # print(\"self_loop\")\n",
    "        graph = dgl.remove_self_loop(graph)\n",
    "        graph = dgl.add_self_loop(graph)\n",
    "    n_edges = graph.num_edges()\n",
    "\n",
    "    if args.gpu >= 0:\n",
    "        graph = graph.to(args.gpu)\n",
    "    # create DGI model\n",
    "    dgi = DGI(\n",
    "        graph,\n",
    "        in_feats,\n",
    "        args.n_hidden,\n",
    "        args.n_layers,\n",
    "        nn.PReLU(args.n_hidden),\n",
    "        args.dropout,\n",
    "    )\n",
    "\n",
    "    if cuda:\n",
    "        dgi.cuda()\n",
    "\n",
    "    dgi_optimizer = torch.optim.Adam(\n",
    "        dgi.parameters(), lr=args.dgi_lr, weight_decay=args.weight_decay\n",
    "    )\n",
    "\n",
    "    # train deep graph infomax\n",
    "    cnt_wait = 0\n",
    "    best = 1e9\n",
    "    best_t = 0\n",
    "    dur = []\n",
    "    for epoch in range(args.n_dgi_epochs):\n",
    "        dgi.train()\n",
    "        if epoch >= 3:\n",
    "            t0 = time.time()\n",
    "\n",
    "        dgi_optimizer.zero_grad()\n",
    "        loss = dgi(features)\n",
    "        loss.backward()\n",
    "        dgi_optimizer.step()\n",
    "\n",
    "        if loss < best:\n",
    "            best = loss\n",
    "            best_t = epoch\n",
    "            cnt_wait = 0\n",
    "            torch.save(dgi.state_dict(), \"best_dgi.pkl\")\n",
    "        else:\n",
    "            cnt_wait += 1\n",
    "\n",
    "        if cnt_wait == args.patience:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "        if epoch >= 3:\n",
    "            dur.append(time.time() - t0)\n",
    "\n",
    "        \"\"\" print(\n",
    "            \"Epoch {:05d} | Time(s) {:.4f} | Loss {:.4f} | \"\n",
    "            \"ETputs(KTEPS) {:.2f}\".format(\n",
    "                epoch, np.mean(dur), loss.item(), n_edges / np.mean(dur) / 1000\n",
    "            )\n",
    "        ) \"\"\"\n",
    "\n",
    "    embeds = dgi.encoder(features, corrupt=False)\n",
    "    embeds = embeds.cpu().detach()\n",
    "\n",
    "    df_node_embeddings = pd.DataFrame(data=embeds)\n",
    "    df_node_embeddings\n",
    "\n",
    "    # save\n",
    "    df_node_embeddings.to_csv(\"{}/output/node_embeddings/node-embeddings_{}_{}_{}_{}.csv\".format(dir, group, subgroup, method, dimension), index=True)\n",
    "    # print(\"Save node embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=6234, num_edges=1242263,\n",
      "      ndata_schemes={'feat': Scheme(shape=(1,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.float32), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}\n",
      "      edata_schemes={'weight': Scheme(shape=(), dtype=torch.float64)})\n",
      "time: 322 ms (started: 2023-06-01 12:57:02 -05:00)\n"
     ]
    }
   ],
   "source": [
    "nodes_data = pd.read_csv(\"{}/output/preprocessing/graphs_data/nodes_data_{}_{}.csv\".format(dir, groups_id[0], subgroups_id[0][0]))\n",
    "edges_data = pd.read_csv(\"{}/output/preprocessing/graphs_data/edges_data_{}_{}.csv\".format(dir, groups_id[0], subgroups_id[0][0]))\n",
    "\n",
    "dataset = CustomDataset(\"g1\", nodes_data, edges_data)\n",
    "graph = dataset[0]\n",
    "\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset='cora', dropout=0.0, gpu=0, dgi_lr=0.001, classifier_lr=0.01, n_dgi_epochs=300, n_classifier_epochs=300, n_hidden=3, n_layers=3, weight_decay=0.0, patience=20, self_loop=True)\n",
      "time: 5.32 ms (started: 2023-06-01 12:57:02 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# params\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"DGI\")\n",
    "# register_data_args(parser)\n",
    "parser.add_argument(\n",
    "    \"--dataset\",\n",
    "    type=str,\n",
    "    default=\"cora\",\n",
    "    required=False,\n",
    "    help=\"The input dataset. Can be cora, citeseer, pubmed, syn(synthetic dataset) or reddit\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--dropout\", type=float, default=0.0, help=\"dropout probability\"\n",
    ")\n",
    "parser.add_argument(\"--gpu\", type=int, default=0, help=\"gpu\")\n",
    "parser.add_argument(\n",
    "    \"--dgi-lr\", type=float, default=1e-3, help=\"dgi learning rate\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--classifier-lr\",\n",
    "    type=float,\n",
    "    default=1e-2,\n",
    "    help=\"classifier learning rate\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n-dgi-epochs\",\n",
    "    type=int,\n",
    "    default=300,\n",
    "    help=\"number of training epochs\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n-classifier-epochs\",\n",
    "    type=int,\n",
    "    default=300,\n",
    "    help=\"number of training epochs\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n-hidden\", type=int, default=2, help=\"number of hidden gcn units\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n-layers\", type=int, default=3, help=\"number of hidden gcn layers\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--weight-decay\", type=float, default=0.0, help=\"Weight for L2 loss\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--patience\", type=int, default=20, help=\"early stop patience condition\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--self-loop\",\n",
    "    action=\"store_true\",\n",
    "    help=\"graph self-loop (default=False)\",\n",
    ")\n",
    "parser.set_defaults(self_loop=True)\n",
    "parser.set_defaults(n_hidden=dimension)\n",
    "parser.set_defaults(n_layers=3)\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/ealvarez/miniconda3/envs/Conda_dgl_3.10/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/Project/GNN_Filter/GNN_unsupervised/output/node_embeddings/node-embeddings_WT_1_dgi_3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/miniconda3/envs/Conda_dgl_3.10/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/Project/GNN_Filter/GNN_unsupervised/output/node_embeddings/node-embeddings_WT_2_dgi_3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/miniconda3/envs/Conda_dgl_3.10/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/Project/GNN_Filter/GNN_unsupervised/output/node_embeddings/node-embeddings_WT_3_dgi_3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/miniconda3/envs/Conda_dgl_3.10/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/Project/GNN_Filter/GNN_unsupervised/output/node_embeddings/node-embeddings_WT_4_dgi_3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/miniconda3/envs/Conda_dgl_3.10/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "100%|██████████| 5/5 [00:32<00:00,  6.43s/it]\n",
      "1it [00:32, 32.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/Project/GNN_Filter/GNN_unsupervised/output/node_embeddings/node-embeddings_WT_5_dgi_3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/miniconda3/envs/Conda_dgl_3.10/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/Project/GNN_Filter/GNN_unsupervised/output/node_embeddings/node-embeddings_zwf1^_1_dgi_3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/miniconda3/envs/Conda_dgl_3.10/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/Project/GNN_Filter/GNN_unsupervised/output/node_embeddings/node-embeddings_zwf1^_2_dgi_3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/miniconda3/envs/Conda_dgl_3.10/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "100%|██████████| 3/3 [00:18<00:00,  6.26s/it]\n",
      "2it [00:50, 24.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping!\n",
      "/home/ealvarez/Project/GNN_Filter/GNN_unsupervised/output/node_embeddings/node-embeddings_zwf1^_3_dgi_3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/miniconda3/envs/Conda_dgl_3.10/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/Project/GNN_Filter/GNN_unsupervised/output/node_embeddings/node-embeddings_pck1^_1_dgi_3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/miniconda3/envs/Conda_dgl_3.10/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "100%|██████████| 2/2 [00:12<00:00,  6.23s/it]\n",
      "3it [01:03, 21.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/Project/GNN_Filter/GNN_unsupervised/output/node_embeddings/node-embeddings_pck1^_2_dgi_3.csv\n",
      "time: 1min 3s (started: 2023-06-01 12:57:02 -05:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# get node embeddings\n",
    "for i, group in tqdm(enumerate(groups_id)):\n",
    "    for subgroup in tqdm(subgroups_id[i]):\n",
    "        nodes_data = pd.read_csv(\"{}/output/preprocessing/graphs_data/nodes_data_{}_{}.csv\".format(dir, group, subgroup))\n",
    "        edges_data = pd.read_csv(\"{}/output/preprocessing/graphs_data/edges_data_{}_{}.csv\".format(dir, group, subgroup))\n",
    "\n",
    "        # read dataset\n",
    "        # data = load_data(args)\n",
    "        data = CustomDataset(\"g_{}_{}\".format(group, subgroup), nodes_data, edges_data)\n",
    "        graph = data[0]\n",
    "\n",
    "        # train\n",
    "        train_dgi(graph, args, method, dimension, group, subgroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.073424</td>\n",
       "      <td>0.172263</td>\n",
       "      <td>-0.062687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.039612</td>\n",
       "      <td>0.172351</td>\n",
       "      <td>-0.106735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.073348</td>\n",
       "      <td>0.172267</td>\n",
       "      <td>-0.062793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.032020</td>\n",
       "      <td>0.172529</td>\n",
       "      <td>-0.116904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059971</td>\n",
       "      <td>0.172594</td>\n",
       "      <td>-0.080733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6229</th>\n",
       "      <td>-0.145494</td>\n",
       "      <td>0.140024</td>\n",
       "      <td>-0.291249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6230</th>\n",
       "      <td>0.307178</td>\n",
       "      <td>0.137017</td>\n",
       "      <td>0.303252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6231</th>\n",
       "      <td>0.426540</td>\n",
       "      <td>0.146321</td>\n",
       "      <td>0.441576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6232</th>\n",
       "      <td>0.461566</td>\n",
       "      <td>0.125687</td>\n",
       "      <td>0.523122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6233</th>\n",
       "      <td>1.299587</td>\n",
       "      <td>-0.000974</td>\n",
       "      <td>1.837837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6234 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2\n",
       "0     0.073424  0.172263 -0.062687\n",
       "1     0.039612  0.172351 -0.106735\n",
       "2     0.073348  0.172267 -0.062793\n",
       "3     0.032020  0.172529 -0.116904\n",
       "4     0.059971  0.172594 -0.080733\n",
       "...        ...       ...       ...\n",
       "6229 -0.145494  0.140024 -0.291249\n",
       "6230  0.307178  0.137017  0.303252\n",
       "6231  0.426540  0.146321  0.441576\n",
       "6232  0.461566  0.125687  0.523122\n",
       "6233  1.299587 -0.000974  1.837837\n",
       "\n",
       "[6234 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 23.4 ms (started: 2023-06-01 12:58:06 -05:00)\n"
     ]
    }
   ],
   "source": [
    "df_node_embeddings = pd.read_csv(\"{}/output/node_embeddings/node-embeddings_{}_{}_{}_{}.csv\".format(dir, \n",
    "                                                                                                    groups_id[0], \n",
    "                                                                                                    subgroups_id[0][0],\n",
    "                                                                                                    method, dimension), index_col=0)\n",
    "df_node_embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
