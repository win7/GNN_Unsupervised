{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.17 ms (started: 2023-05-19 20:53:13 -05:00)\n"
     ]
    }
   ],
   "source": [
    "import argparse, time\n",
    "\n",
    "import dgl\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgi import Classifier, DGI\n",
    "from dgl import DGLGraph\n",
    "from dgl.data import load_data, register_data_args, DGLDataset\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "time: 621 µs (started: 2023-05-19 20:53:14 -05:00)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 736 µs (started: 2023-05-19 20:53:14 -05:00)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 719 µs (started: 2023-05-19 20:53:14 -05:00)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 526 µs (started: 2023-05-19 20:53:14 -05:00)\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, features, labels, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/Project/GNN_Filter\n",
      "time: 995 µs (started: 2023-05-19 20:53:14 -05:00)\n"
     ]
    }
   ],
   "source": [
    "dir = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "print(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/Project/GNN_Filter\n",
      "Method:\t\t dgi\n",
      "Group:\t\t ['zwf1^', 3]\n",
      "Subgroup:\t ['1', '2', '3']\n",
      "Dimensions:\t [3]\n",
      "time: 3.63 ms (started: 2023-05-19 20:53:14 -05:00)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "dir = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "print(dir)\n",
    "\n",
    "# Opening JSON file\n",
    "file = open(\"{}/GNN_unsupervised/parameters.json\".format(dir))\n",
    "params = json.load(file)\n",
    "\n",
    "method = params[\"method\"][params[\"method_idx\"]]\n",
    "print(\"Method:\\t\\t\", method)\n",
    "\n",
    "group = params[\"group\"][params[\"group_idx\"]]\n",
    "print(\"Group:\\t\\t\", group)\n",
    "\n",
    "subgroups = [str(k + 1) for k in range(group[1])]\n",
    "print(\"Subgroup:\\t\", subgroups)\n",
    "\n",
    "dimensions = params[\"dimensions\"]\n",
    "print(\"Dimensions:\\t\", dimensions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.02 ms (started: 2023-05-19 20:53:14 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Custom dataset\n",
    "\n",
    "class CustomDataset(DGLDataset):\n",
    "    def __init__(self, name, dir, group, subgroup):\n",
    "        self.dir = dir\n",
    "        self.group = group\n",
    "        self.subgroup = subgroup\n",
    "        super().__init__(name=name)\n",
    "       \n",
    "    def process(self):\n",
    "        nodes_data = pd.read_csv(\"{}/output_preprocessing/graph_data/{}_nodes_data_{}.csv\".format(self.dir, self.group, self.subgroup))\n",
    "        edges_data = pd.read_csv(\"{}/output_preprocessing/graph_data/{}_edges_data_{}.csv\".format(self.dir, self.group, self.subgroup))\n",
    "        \n",
    "        node_features = torch.from_numpy(nodes_data[\"degree\"].to_numpy())\n",
    "        node_features = node_features.to(torch.float32)\n",
    "        node_features = torch.reshape(node_features, (-1, 1))\n",
    "\n",
    "        node_labels = torch.from_numpy(nodes_data[\"ionMz\"].to_numpy())\n",
    "        node_labels = node_labels.to(torch.float32)\n",
    "\n",
    "        edge_features = torch.from_numpy(edges_data[\"weight\"].to_numpy())\n",
    "        edges_src = torch.from_numpy(edges_data[\"source\"].to_numpy())\n",
    "        edges_dst = torch.from_numpy(edges_data[\"target\"].to_numpy())\n",
    "\n",
    "        self.graph = dgl.graph(\n",
    "            (edges_src, edges_dst), num_nodes=nodes_data.shape[0]\n",
    "        )\n",
    "        self.graph.ndata[\"feat\"] = node_features\n",
    "        self.graph.ndata[\"label\"] = node_labels\n",
    "        self.graph.edata[\"weight\"] = edge_features\n",
    "\n",
    "        # If your dataset is a node classification dataset, you will need to assign\n",
    "        # masks indicating whether a node belongs to training, validation, and test set.\n",
    "        n_nodes = nodes_data.shape[0]\n",
    "        n_train = int(n_nodes * 0.6)\n",
    "        n_val = int(n_nodes * 0.2)\n",
    "        train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        val_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        train_mask[:n_train] = True\n",
    "        val_mask[n_train : n_train + n_val] = True\n",
    "        test_mask[n_train + n_val :] = True\n",
    "        self.graph.ndata[\"train_mask\"] = train_mask\n",
    "        self.graph.ndata[\"val_mask\"] = val_mask\n",
    "        self.graph.ndata[\"test_mask\"] = test_mask\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.graph\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=6231, num_edges=2525491,\n",
      "      ndata_schemes={'feat': Scheme(shape=(1,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.float32), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}\n",
      "      edata_schemes={'weight': Scheme(shape=(), dtype=torch.float64)})\n",
      "time: 415 ms (started: 2023-05-19 20:53:14 -05:00)\n"
     ]
    }
   ],
   "source": [
    "dataset = CustomDataset(\"g1\", dir, group[0], 1)\n",
    "graph = dataset[0]\n",
    "\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset='cora', dropout=0.0, gpu=0, dgi_lr=0.001, classifier_lr=0.01, n_dgi_epochs=300, n_classifier_epochs=300, n_hidden=2, n_layers=3, weight_decay=0.0, patience=20, self_loop=False)\n",
      "time: 4.61 ms (started: 2023-05-19 20:53:15 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Params\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"DGI\")\n",
    "# register_data_args(parser)\n",
    "parser.add_argument(\n",
    "    \"--dataset\",\n",
    "    type=str,\n",
    "    default=\"cora\",\n",
    "    required=False,\n",
    "    help=\"The input dataset. Can be cora, citeseer, pubmed, syn(synthetic dataset) or reddit\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--dropout\", type=float, default=0.0, help=\"dropout probability\"\n",
    ")\n",
    "parser.add_argument(\"--gpu\", type=int, default=0, help=\"gpu\")\n",
    "parser.add_argument(\n",
    "    \"--dgi-lr\", type=float, default=1e-3, help=\"dgi learning rate\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--classifier-lr\",\n",
    "    type=float,\n",
    "    default=1e-2,\n",
    "    help=\"classifier learning rate\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n-dgi-epochs\",\n",
    "    type=int,\n",
    "    default=300,\n",
    "    help=\"number of training epochs\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n-classifier-epochs\",\n",
    "    type=int,\n",
    "    default=300,\n",
    "    help=\"number of training epochs\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n-hidden\", type=int, default=2, help=\"number of hidden gcn units\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n-layers\", type=int, default=3, help=\"number of hidden gcn layers\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--weight-decay\", type=float, default=0.0, help=\"Weight for L2 loss\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--patience\", type=int, default=20, help=\"early stop patience condition\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--self-loop\",\n",
    "    action=\"store_true\",\n",
    "    help=\"graph self-loop (default=False)\",\n",
    ")\n",
    "parser.set_defaults(self_loop=False)\n",
    "args = parser.parse_args(\"\")\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6231, 1])\n",
      "self_loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/miniconda3/envs/Conda_dgl_3.10/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      " 33%|███▎      | 1/3 [00:06<00:13,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6226, 1])\n",
      "self_loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/miniconda3/envs/Conda_dgl_3.10/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      " 67%|██████▋   | 2/3 [00:15<00:07,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6216, 1])\n",
      "self_loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/miniconda3/envs/Conda_dgl_3.10/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "100%|██████████| 3/3 [00:26<00:00,  8.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 26.3 s (started: 2023-05-19 20:53:15 -05:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get node embeddings\n",
    "\n",
    "for dimension in dimensions:\n",
    "    # Get embeddings\n",
    "    parser.set_defaults(self_loop=True)\n",
    "    parser.set_defaults(n_hidden=dimension)\n",
    "    parser.set_defaults(n_layers=3)\n",
    "    args = parser.parse_args(\"\")\n",
    "    # print(args)\n",
    "    \n",
    "    for i in tqdm(subgroups):\n",
    "        # Read dataset\n",
    "\n",
    "        # load and preprocess dataset\n",
    "        # data = load_data(args)\n",
    "        data = CustomDataset(\"g\".format(i), dir, group[0], i)\n",
    "\n",
    "        g = data[0]\n",
    "        # print(\"x\", g)\n",
    "\n",
    "        features = torch.FloatTensor(np.log10(g.ndata[\"feat\"]))\n",
    "        print(features.shape)\n",
    "        # labels = torch.LongTensor(g.ndata[\"label\"])\n",
    "        if hasattr(torch, \"BoolTensor\"):\n",
    "            train_mask = torch.BoolTensor(g.ndata[\"train_mask\"])\n",
    "            val_mask = torch.BoolTensor(g.ndata[\"val_mask\"])\n",
    "            test_mask = torch.BoolTensor(g.ndata[\"test_mask\"])\n",
    "        else:\n",
    "            train_mask = torch.ByteTensor(g.ndata[\"train_mask\"])\n",
    "            val_mask = torch.ByteTensor(g.ndata[\"val_mask\"])\n",
    "            test_mask = torch.ByteTensor(g.ndata[\"test_mask\"])\n",
    "        in_feats = features.shape[1]\n",
    "        # n_classes = data.num_classes\n",
    "        n_edges = g.num_edges()\n",
    "\n",
    "        if args.gpu < 0:\n",
    "            cuda = False\n",
    "        else:\n",
    "            cuda = True\n",
    "            torch.cuda.set_device(args.gpu)\n",
    "            features = features.cuda()\n",
    "            # labels = labels.cuda()\n",
    "            train_mask = train_mask.cuda()\n",
    "            val_mask = val_mask.cuda()\n",
    "            test_mask = test_mask.cuda()\n",
    "\n",
    "        # add self loop\n",
    "        if args.self_loop:\n",
    "            print(\"self_loop\")\n",
    "            g = dgl.remove_self_loop(g)\n",
    "            g = dgl.add_self_loop(g)\n",
    "        n_edges = g.num_edges()\n",
    "\n",
    "        if args.gpu >= 0:\n",
    "            g = g.to(args.gpu)\n",
    "        # create DGI model\n",
    "        dgi = DGI(\n",
    "            g,\n",
    "            in_feats,\n",
    "            args.n_hidden,\n",
    "            args.n_layers,\n",
    "            nn.PReLU(args.n_hidden),\n",
    "            args.dropout,\n",
    "        )\n",
    "\n",
    "        if cuda:\n",
    "            dgi.cuda()\n",
    "\n",
    "        dgi_optimizer = torch.optim.Adam(\n",
    "            dgi.parameters(), lr=args.dgi_lr, weight_decay=args.weight_decay\n",
    "        )\n",
    "\n",
    "        # train deep graph infomax\n",
    "        cnt_wait = 0\n",
    "        best = 1e9\n",
    "        best_t = 0\n",
    "        dur = []\n",
    "        for epoch in range(args.n_dgi_epochs):\n",
    "            dgi.train()\n",
    "            if epoch >= 3:\n",
    "                t0 = time.time()\n",
    "\n",
    "            dgi_optimizer.zero_grad()\n",
    "            loss = dgi(features)\n",
    "            loss.backward()\n",
    "            dgi_optimizer.step()\n",
    "\n",
    "            if loss < best:\n",
    "                best = loss\n",
    "                best_t = epoch\n",
    "                cnt_wait = 0\n",
    "                torch.save(dgi.state_dict(), \"best_dgi.pkl\")\n",
    "            else:\n",
    "                cnt_wait += 1\n",
    "\n",
    "            if cnt_wait == args.patience:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "\n",
    "            if epoch >= 3:\n",
    "                dur.append(time.time() - t0)\n",
    "\n",
    "            \"\"\" print(\n",
    "                \"Epoch {:05d} | Time(s) {:.4f} | Loss {:.4f} | \"\n",
    "                \"ETputs(KTEPS) {:.2f}\".format(\n",
    "                    epoch, np.mean(dur), loss.item(), n_edges / np.mean(dur) / 1000\n",
    "                )\n",
    "            ) \"\"\"\n",
    "\n",
    "        embeds = dgi.encoder(features, corrupt=False)\n",
    "        embeds = embeds.cpu().detach()\n",
    "\n",
    "        df_node_embeddings = pd.DataFrame(data=embeds)\n",
    "        df_node_embeddings\n",
    "\n",
    "        # save\n",
    "        df_node_embeddings.to_csv(\"{}/output_{}/node_embeddings/{}_node-embeddings_{}_{}.csv\".format(dir, method, group[0], dimension, i), index=True)\n",
    "        # print(\"Save node embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.068948</td>\n",
       "      <td>0.121718</td>\n",
       "      <td>-0.035491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.034820</td>\n",
       "      <td>0.121082</td>\n",
       "      <td>-0.081500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.086121</td>\n",
       "      <td>0.122290</td>\n",
       "      <td>-0.012798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.081040</td>\n",
       "      <td>0.122028</td>\n",
       "      <td>-0.019343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.020286</td>\n",
       "      <td>0.121121</td>\n",
       "      <td>-0.157732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6226</th>\n",
       "      <td>0.023970</td>\n",
       "      <td>0.084081</td>\n",
       "      <td>-0.030308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6227</th>\n",
       "      <td>0.271349</td>\n",
       "      <td>0.102144</td>\n",
       "      <td>0.280583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6228</th>\n",
       "      <td>0.688393</td>\n",
       "      <td>0.064346</td>\n",
       "      <td>0.925769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6229</th>\n",
       "      <td>0.285655</td>\n",
       "      <td>0.101263</td>\n",
       "      <td>0.301629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6230</th>\n",
       "      <td>-0.377535</td>\n",
       "      <td>0.015855</td>\n",
       "      <td>-0.464911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6231 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2\n",
       "0     0.068948  0.121718 -0.035491\n",
       "1     0.034820  0.121082 -0.081500\n",
       "2     0.086121  0.122290 -0.012798\n",
       "3     0.081040  0.122028 -0.019343\n",
       "4    -0.020286  0.121121 -0.157732\n",
       "...        ...       ...       ...\n",
       "6226  0.023970  0.084081 -0.030308\n",
       "6227  0.271349  0.102144  0.280583\n",
       "6228  0.688393  0.064346  0.925769\n",
       "6229  0.285655  0.101263  0.301629\n",
       "6230 -0.377535  0.015855 -0.464911\n",
       "\n",
       "[6231 rows x 3 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 19.1 ms (started: 2023-05-19 20:53:41 -05:00)\n"
     ]
    }
   ],
   "source": [
    "df_node_embeddings = pd.read_csv(\"{}/output_{}/node_embeddings/{}_node-embeddings_{}_{}.csv\".format(dir, method, group[0], 3, 1), index_col=0)\n",
    "df_node_embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
