{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.16 ms (started: 2023-05-18 20:24:57 -05:00)\n"
     ]
    }
   ],
   "source": [
    "import argparse, time\n",
    "\n",
    "import dgl\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgi import Classifier, DGI\n",
    "from dgl import DGLGraph\n",
    "from dgl.data import load_data, register_data_args, DGLDataset\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "time: 1 ms (started: 2023-05-18 20:24:58 -05:00)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 723 µs (started: 2023-05-18 20:24:58 -05:00)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 546 µs (started: 2023-05-18 20:24:58 -05:00)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.14 ms (started: 2023-05-18 20:24:58 -05:00)\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, features, labels, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "  \n",
    "# Opening JSON file\n",
    "file = open(\"parameters.json\")\n",
    "params = json.load(file)\n",
    "\n",
    "dir = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "print(dir)\n",
    "\n",
    "method = params[\"method\"][params[\"method_idx\"]]\n",
    "print(\"Method:\\t\\t\", method)\n",
    "\n",
    "group = params[\"group\"][params[\"group_idx\"]]\n",
    "print(\"Group:\\t\\t\", group)\n",
    "\n",
    "subgroups = [str(k + 1) for k in range(group[1])]\n",
    "print(\"Subgroup:\\t\", subgroups)\n",
    "\n",
    "dimensions = params[\"dimensions\"]\n",
    "print(\"Dimensions:\\t\", dimensions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.88 ms (started: 2023-05-18 20:24:58 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Custom dataset\n",
    "\n",
    "class CustomDataset(DGLDataset):\n",
    "    def __init__(self, name, dir, group, subgroup):\n",
    "        self.dir = dir\n",
    "        self.group = group\n",
    "        self.subgroup = subgroup\n",
    "        super().__init__(name=name)\n",
    "       \n",
    "    def process(self):\n",
    "        nodes_data = pd.read_csv(\"{}/output_preprocessing/graph_data/{}_nodes_data_{}.csv\".format(self.dir, self.group, self.subgroup))\n",
    "        edges_data = pd.read_csv(\"{}/output_preprocessing/graph_data/{}_edges_data_{}.csv\".format(self.dir, self.group, self.subgroup))\n",
    "        \n",
    "        node_features = torch.from_numpy(nodes_data[\"degree\"].to_numpy())\n",
    "        node_features = node_features.to(torch.float32)\n",
    "        node_features = torch.reshape(node_features, (-1, 1))\n",
    "\n",
    "        node_labels = torch.from_numpy(nodes_data[\"ionMz\"].to_numpy())\n",
    "        node_labels = node_labels.to(torch.float32)\n",
    "\n",
    "        edge_features = torch.from_numpy(edges_data[\"weight\"].to_numpy())\n",
    "        edges_src = torch.from_numpy(edges_data[\"source\"].to_numpy())\n",
    "        edges_dst = torch.from_numpy(edges_data[\"target\"].to_numpy())\n",
    "\n",
    "        self.graph = dgl.graph(\n",
    "            (edges_src, edges_dst), num_nodes=nodes_data.shape[0]\n",
    "        )\n",
    "        self.graph.ndata[\"feat\"] = node_features\n",
    "        self.graph.ndata[\"label\"] = node_labels\n",
    "        self.graph.edata[\"weight\"] = edge_features\n",
    "\n",
    "        # If your dataset is a node classification dataset, you will need to assign\n",
    "        # masks indicating whether a node belongs to training, validation, and test set.\n",
    "        n_nodes = nodes_data.shape[0]\n",
    "        n_train = int(n_nodes * 0.6)\n",
    "        n_val = int(n_nodes * 0.2)\n",
    "        train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        val_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        train_mask[:n_train] = True\n",
    "        val_mask[n_train : n_train + n_val] = True\n",
    "        test_mask[n_train + n_val :] = True\n",
    "        self.graph.ndata[\"train_mask\"] = train_mask\n",
    "        self.graph.ndata[\"val_mask\"] = val_mask\n",
    "        self.graph.ndata[\"test_mask\"] = test_mask\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.graph\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=6234, num_edges=1243057,\n",
      "      ndata_schemes={'feat': Scheme(shape=(1,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.float32), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}\n",
      "      edata_schemes={'weight': Scheme(shape=(), dtype=torch.float64)})\n",
      "time: 222 ms (started: 2023-05-18 20:24:59 -05:00)\n"
     ]
    }
   ],
   "source": [
    "dataset = CustomDataset(\"g1\", dir, group[0], 1)\n",
    "graph = dataset[0]\n",
    "\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset='cora', dropout=0.0, gpu=0, dgi_lr=0.001, classifier_lr=0.01, n_dgi_epochs=300, n_classifier_epochs=300, n_hidden=2, n_layers=3, weight_decay=0.0, patience=20, self_loop=False)\n",
      "time: 3.53 ms (started: 2023-05-18 20:24:59 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Params\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"DGI\")\n",
    "# register_data_args(parser)\n",
    "parser.add_argument(\n",
    "    \"--dataset\",\n",
    "    type=str,\n",
    "    default=\"cora\",\n",
    "    required=False,\n",
    "    help=\"The input dataset. Can be cora, citeseer, pubmed, syn(synthetic dataset) or reddit\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--dropout\", type=float, default=0.0, help=\"dropout probability\"\n",
    ")\n",
    "parser.add_argument(\"--gpu\", type=int, default=0, help=\"gpu\")\n",
    "parser.add_argument(\n",
    "    \"--dgi-lr\", type=float, default=1e-3, help=\"dgi learning rate\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--classifier-lr\",\n",
    "    type=float,\n",
    "    default=1e-2,\n",
    "    help=\"classifier learning rate\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n-dgi-epochs\",\n",
    "    type=int,\n",
    "    default=300,\n",
    "    help=\"number of training epochs\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n-classifier-epochs\",\n",
    "    type=int,\n",
    "    default=300,\n",
    "    help=\"number of training epochs\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n-hidden\", type=int, default=2, help=\"number of hidden gcn units\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n-layers\", type=int, default=3, help=\"number of hidden gcn layers\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--weight-decay\", type=float, default=0.0, help=\"Weight for L2 loss\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--patience\", type=int, default=20, help=\"early stop patience condition\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--self-loop\",\n",
    "    action=\"store_true\",\n",
    "    help=\"graph self-loop (default=False)\",\n",
    ")\n",
    "parser.set_defaults(self_loop=False)\n",
    "args = parser.parse_args(\"\")\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6234, 1])\n",
      "self_loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/miniconda3/envs/Conda_dgl_3.10/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      " 20%|██        | 1/5 [00:04<00:19,  4.75s/it]/home/ealvarez/miniconda3/envs/Conda_dgl_3.10/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6231, 1])\n",
      "self_loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:09<00:14,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6233, 1])\n",
      "self_loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/miniconda3/envs/Conda_dgl_3.10/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      " 60%|██████    | 3/5 [00:15<00:10,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6226, 1])\n",
      "self_loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/miniconda3/envs/Conda_dgl_3.10/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      " 80%|████████  | 4/5 [00:20<00:05,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6226, 1])\n",
      "self_loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/miniconda3/envs/Conda_dgl_3.10/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "100%|██████████| 5/5 [00:26<00:00,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 26.5 s (started: 2023-05-18 20:24:59 -05:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get node embeddings\n",
    "\n",
    "# list_embeddings_time = []\n",
    "for dimension in dimensions:\n",
    "    # Get embeddings\n",
    "    parser.set_defaults(self_loop=True)\n",
    "    parser.set_defaults(n_hidden=dimension)\n",
    "    parser.set_defaults(n_layers=3)\n",
    "    args = parser.parse_args(\"\")\n",
    "    # print(args)\n",
    "    \n",
    "    for i in tqdm(subgroups):\n",
    "        # Read dataset\n",
    "\n",
    "        # load and preprocess dataset\n",
    "        # data = load_data(args)\n",
    "        data = CustomDataset(\"g\".format(i), dir, group[0], i)\n",
    "\n",
    "        g = data[0]\n",
    "        # print(\"x\", g)\n",
    "\n",
    "        features = torch.FloatTensor(np.log10(g.ndata[\"feat\"]))\n",
    "        print(features.shape)\n",
    "        # labels = torch.LongTensor(g.ndata[\"label\"])\n",
    "        if hasattr(torch, \"BoolTensor\"):\n",
    "            train_mask = torch.BoolTensor(g.ndata[\"train_mask\"])\n",
    "            val_mask = torch.BoolTensor(g.ndata[\"val_mask\"])\n",
    "            test_mask = torch.BoolTensor(g.ndata[\"test_mask\"])\n",
    "        else:\n",
    "            train_mask = torch.ByteTensor(g.ndata[\"train_mask\"])\n",
    "            val_mask = torch.ByteTensor(g.ndata[\"val_mask\"])\n",
    "            test_mask = torch.ByteTensor(g.ndata[\"test_mask\"])\n",
    "        in_feats = features.shape[1]\n",
    "        # n_classes = data.num_classes\n",
    "        n_edges = g.num_edges()\n",
    "\n",
    "        if args.gpu < 0:\n",
    "            cuda = False\n",
    "        else:\n",
    "            cuda = True\n",
    "            torch.cuda.set_device(args.gpu)\n",
    "            features = features.cuda()\n",
    "            # labels = labels.cuda()\n",
    "            train_mask = train_mask.cuda()\n",
    "            val_mask = val_mask.cuda()\n",
    "            test_mask = test_mask.cuda()\n",
    "\n",
    "        # add self loop\n",
    "        if args.self_loop:\n",
    "            print(\"self_loop\")\n",
    "            g = dgl.remove_self_loop(g)\n",
    "            g = dgl.add_self_loop(g)\n",
    "        n_edges = g.num_edges()\n",
    "\n",
    "        if args.gpu >= 0:\n",
    "            g = g.to(args.gpu)\n",
    "        # create DGI model\n",
    "        dgi = DGI(\n",
    "            g,\n",
    "            in_feats,\n",
    "            args.n_hidden,\n",
    "            args.n_layers,\n",
    "            nn.PReLU(args.n_hidden),\n",
    "            args.dropout,\n",
    "        )\n",
    "\n",
    "        if cuda:\n",
    "            dgi.cuda()\n",
    "\n",
    "        dgi_optimizer = torch.optim.Adam(\n",
    "            dgi.parameters(), lr=args.dgi_lr, weight_decay=args.weight_decay\n",
    "        )\n",
    "\n",
    "        # train deep graph infomax\n",
    "        cnt_wait = 0\n",
    "        best = 1e9\n",
    "        best_t = 0\n",
    "        dur = []\n",
    "        for epoch in range(args.n_dgi_epochs):\n",
    "            dgi.train()\n",
    "            if epoch >= 3:\n",
    "                t0 = time.time()\n",
    "\n",
    "            dgi_optimizer.zero_grad()\n",
    "            loss = dgi(features)\n",
    "            loss.backward()\n",
    "            dgi_optimizer.step()\n",
    "\n",
    "            if loss < best:\n",
    "                best = loss\n",
    "                best_t = epoch\n",
    "                cnt_wait = 0\n",
    "                torch.save(dgi.state_dict(), \"best_dgi.pkl\")\n",
    "            else:\n",
    "                cnt_wait += 1\n",
    "\n",
    "            if cnt_wait == args.patience:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "\n",
    "            if epoch >= 3:\n",
    "                dur.append(time.time() - t0)\n",
    "\n",
    "            \"\"\" print(\n",
    "                \"Epoch {:05d} | Time(s) {:.4f} | Loss {:.4f} | \"\n",
    "                \"ETputs(KTEPS) {:.2f}\".format(\n",
    "                    epoch, np.mean(dur), loss.item(), n_edges / np.mean(dur) / 1000\n",
    "                )\n",
    "            ) \"\"\"\n",
    "\n",
    "        embeds = dgi.encoder(features, corrupt=False)\n",
    "        embeds = embeds.cpu().detach()\n",
    "\n",
    "        df_node_embeddings = pd.DataFrame(data=embeds)\n",
    "        df_node_embeddings\n",
    "\n",
    "        # save\n",
    "        df_node_embeddings.to_csv(\"{}/output_{}/node_embeddings/{}_node-embeddings_{}_{}.csv\".format(dir, method, group[0], dimension, i), index=True)\n",
    "        # print(\"Save node embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.073444</td>\n",
       "      <td>0.171685</td>\n",
       "      <td>-0.062233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.039632</td>\n",
       "      <td>0.171730</td>\n",
       "      <td>-0.106279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.073368</td>\n",
       "      <td>0.171690</td>\n",
       "      <td>-0.062339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.032038</td>\n",
       "      <td>0.171898</td>\n",
       "      <td>-0.116451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059988</td>\n",
       "      <td>0.171999</td>\n",
       "      <td>-0.080284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6229</th>\n",
       "      <td>-0.025069</td>\n",
       "      <td>0.144772</td>\n",
       "      <td>-0.143681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6230</th>\n",
       "      <td>0.304509</td>\n",
       "      <td>0.137119</td>\n",
       "      <td>0.299618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6231</th>\n",
       "      <td>0.419120</td>\n",
       "      <td>0.147069</td>\n",
       "      <td>0.430878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6232</th>\n",
       "      <td>0.445898</td>\n",
       "      <td>0.127435</td>\n",
       "      <td>0.500044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6233</th>\n",
       "      <td>1.282833</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>1.813835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6234 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2\n",
       "0     0.073444  0.171685 -0.062233\n",
       "1     0.039632  0.171730 -0.106279\n",
       "2     0.073368  0.171690 -0.062339\n",
       "3     0.032038  0.171898 -0.116451\n",
       "4     0.059988  0.171999 -0.080284\n",
       "...        ...       ...       ...\n",
       "6229 -0.025069  0.144772 -0.143681\n",
       "6230  0.304509  0.137119  0.299618\n",
       "6231  0.419120  0.147069  0.430878\n",
       "6232  0.445898  0.127435  0.500044\n",
       "6233  1.282833  0.001784  1.813835\n",
       "\n",
       "[6234 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 19.4 ms (started: 2023-05-18 20:25:26 -05:00)\n"
     ]
    }
   ],
   "source": [
    "df_node_embeddings = pd.read_csv(\"{}/output_{}/node_embeddings/{}_node-embeddings_{}_{}.csv\".format(dir, method, group[0], 3, 1), index_col=0)\n",
    "df_node_embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
